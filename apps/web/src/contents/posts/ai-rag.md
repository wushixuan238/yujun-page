---
title: "RAG是什么？"  
category: "AI"  
publishedAt: "2025-03-20"  
summary: "RAG"  
tags:  
  - AI    
banner: /images/banner/posts/ai/rag.png 
alt: "图片替代文本"  
mathjax: false
---


# RAG是什么？

可以简单的理解为两个核心阶段：离线阶段和在线阶段。

其中，离线阶段是我们预先完成的，即建立索引的阶段。具体来说主要分为以下两步：
- 解析并且切片。
- 向量存储。

说白了就是，首先，我们会有一堆原始的知识文件，比如公司的内部手册、产品文档、法律条文或者大量的报告。
系统会先将这些完整的文档进行解析，然后切割成一个个更小、更易于管理和理解的一个知识片段（Chunks）。

接下来，我们的系统就需要让计算机理解每个知识片段的**语义含义**。这里会使用一个专门的Embedding Model，将每一个文本片段转换成tokens，其实就是向量（Vector）。

内容相近的文本片段，其对应的数值在空间上的距离也更近。
最后，系统将所有知识片段的向量连同原文一起，存入一个专门的数据库，即向量数据库。

至此，离线阶段完成。

然后，进入检索生成阶段，这个阶段是实时的，当用户提出问题时会触发。可以理解为如下几个阶段：
- 用户提出问题。
- 进行检索召回。
- 生成答案。

就比如，用户向我们系统提出一个具体问题，比如：我们的产品A保修政策是怎样的？

系统首先会像处理知识库的文字一样，将用户的问题也转换成一个向量。然后，系统拿着这个向量去之前建好的向量数据库里进行搜索，找出与它最相似、最相关的几个向量。这个过程就叫**检索或召回**。

系统可能会找到了几个包含“产品A”、“保修”等信息的原始文本片段。

我们的系统不会直接把找到的零散片段丢给用户。它会把用户的原始问题和刚刚检索到的相关文档切片打包在一起，组合成一个更丰富的Prompt。

这个完整的指令被发送给一个LLM（如 GPT-4）。就比如：请根据我提供的这几段参考资料，来回答这个用户问题：‘我们的产品A保修政策是怎样的？

大模型会基于提供的上下文信息，而不是仅仅依赖它自己模糊的通用知识，来生成一个精准、有理有据的答案，并返回给用户。

至此检索-增强-生成（RAG）阶段完成。

简单来说，其实就是通过**先检索，再生成**的方式，赋予了大模型使用外部、特定知识库的能力。
提高了答案的准确性和时效性，有效减少了AI胡说八道（幻觉）的现象，让它能够成为一个基于特定知识的专家问答系统。


这就是RAG，学完整体的思想之后，我们就可以去找一些框架的官方文档，去做一个属于我们自己的领域专家问答系统。

但是，仅仅是开始，先把功能完成，之后，一定要关注量化指标，努力把指标提高的过程，才是我们真正学习RAG的开始，会遇到各种各样的问题，
才能在解决问题中成长。







